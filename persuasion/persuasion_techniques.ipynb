{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqqN9uXO3YDW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install bespokelabs-curator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpEIazgRy0XV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2db073b-c4d3-4ed0-8f86-040c61d3e92f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[05/06/25 02:01:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Requesting text output from gpt-4o, using OpenAI backend                \u001b]8;id=695582;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/_factory.py\u001b\\\u001b[2m_factory.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=992098;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/_factory.py#60\u001b\\\u001b[2m60\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/06/25 02:01:29] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Requesting text output from gpt-4o, using OpenAI backend                <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/_factory.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_factory.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/_factory.py#60\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">60</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from bespokelabs import curator\n",
        "from tqdm import tqdm\n",
        "import pprint\n",
        "from google import genai\n",
        "llm = curator.LLM(model_name=\"gpt-4o\", backend_params={\"max_requests_per_minute\": 200, \"api_key\": ''})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfrDQHQR3Spw"
      },
      "outputs": [],
      "source": [
        "strategies = {\n",
        "    'build_rapport' : \"**Build Rapport:** Establish a respectful and understanding relationship with the Believer (e.g., to ensure the conversation is seen as a friendly exchange rather than a confrontation; demonstrating understanding and empathy towards the individuals beliefs without judgment).\",\n",
        "    'critical_thinking' : \"**Critical Thinking:** Encourage the Believer to question and analyze the logic, evidence, and sources behind their beliefs, promoting a more analytical and reflective approach to information.\",\n",
        "    'alternative_explanations': \"**Alternative Explanations: Provide plausible, evidence-based alternative perspectives or explanations for events or phenomena that are attributed to conspiracy theories.\",\n",
        "    'harm': \"**Harm: Discuss the personal or societal harms of the conspiracy beliefs.\",\n",
        "    'stories':\"**Stories/Examples:** Share stories, anecdotes, or real-world examples.\",\n",
        "    'encourage_empathy':\"**Encourage Empathy:** Help the Believer consider the impact of conspiracy beliefs on others, fostering empathy and a broader perspective.\",\n",
        "    'socratic':\"**Socratic Questioning:** Employ a questioning approach that leads the Believer to reflect on and examine the validity of their beliefs.\",\n",
        "    'conflicting_evidence':\"**Conflicting Evidence:** Introduce facts or data that directly contradict claims made by the conspiracy theory or the Believer.\",\n",
        "    'common_ground':\"**Common Ground/Shared Reality:** Identify and build on beliefs or values that the Debunker shares with the Believer.\",\n",
        "    'psychological_needs':\"**Psychological Needs:** Recognize and address the emotional aspects or psychological needs that may be underlying the Believers attraction to conspiracy theories, such as a desire for control or understanding.\",\n",
        "    'inconsistencies':\"**Inconsistencies/Logical Fallacies:** Identify and discuss logical inconsistencies or fallacies in the conspiracy theorys arguments.\"\n",
        "}\n",
        "\n",
        "\n",
        "PROMPT = \"\"\"\n",
        "  You are about to be shown the text of a written conversation about fake news. Your job is to process the conversation and return a classification of the nature of consultant's arguments. Particularly, you will determine whether the given arguments use the following persuasion strategy:\n",
        "  {strategy}\n",
        "  ** Response Scale **\n",
        "  Use the following response scale for each rating:\n",
        "  1 : Strategy not used.\n",
        "  2 : Strategy used rarely, in a limited fashion.\n",
        "  3 : Strategy used repeatedly or with clear emphasis.\n",
        "  4 : Strategy used extensively and/or centrally throughout the response.”\n",
        "\n",
        "  No need for explanations. Only analyze the Consultant's argument across all the rounds. Output only the correct response value.\n",
        "  *{statement}*\n",
        " \"\"\"\n",
        "\n",
        "\n",
        "PROMPT_Reasoning = \"\"\"\n",
        "You are given a debate transcript and the final judge's reasoning. Your task is to process the transcript and identify if any of the given strategies persuaded the judge to make a decision.\n",
        "  **Critical Thinking:** Encourage the Believer to question and analyze the logic, evidence, and sources behind their beliefs, promoting a more analytical and reflective approach to information.\n",
        "  **Alternative Explanations: Provide plausible, evidence-based alternative perspectives or explanations for events or phenomena that are attributed to conspiracy theories.\n",
        "  **Harm: Discuss the personal or societal harms of the conspiracy beliefs.\n",
        "  **Stories/Examples:** Share stories, anecdotes, or real-world examples.\n",
        "  **Conflicting Evidence:** Introduce facts or data that directly contradict claims made by the conspiracy theory or the Believer.\n",
        "  **Inconsistencies/Logical Fallacies:** Identify and discuss logical inconsistencies or fallacies in the conspiracy theorys arguments.\n",
        "\n",
        "Please give your answer in a brief statement.\n",
        "\n",
        "Debate Transcript:\n",
        "{debate}\n",
        "\n",
        "\n",
        "Judge's Reasoning:\n",
        "{reasoning}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz-B_g5f3o6j"
      },
      "outputs": [],
      "source": [
        "#read data\n",
        "filename = \"/content/drive/MyDrive/Final-transcript-debate-consultancy/Human-debate/debate_all_negative_belief_data.json\"\n",
        "file = open(filename)\n",
        "data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37sGcwb95qUi"
      },
      "outputs": [],
      "source": [
        "#read debate script\n",
        "veracity = []\n",
        "arguments = []\n",
        "humans = []\n",
        "answer_defending = []\n",
        "sessions = []\n",
        "topic = []\n",
        "reasoning = []\n",
        "\n",
        "for human, human_dict in data.items():\n",
        "        for session in human_dict:\n",
        "          humans.append(human)\n",
        "          sessions.append(session['session_id'])\n",
        "          topic.append(session['debate_topic'])\n",
        "          full_argument = ''\n",
        "          reasoning.append(session['reasoning'])\n",
        "          for round in eval(session['rounds']):\n",
        "            # print(round.keys())\n",
        "\n",
        "            veracity.append(round['ground_truth_veracity'])\n",
        "            answer_defending.append(round['debater_positions']['second_debater']['defending'])\n",
        "            # rounds.append(round['round_number'])\n",
        "            full_argument += f\"Round {round['round_number']} \\n\\n Debater A: {round['debater_a_response']} \\n\\n Debater B: {round['debater_b_response']} \\n\\n Judge's Question: {round['judge_feedback']} \\n\\n\"\n",
        "          arguments.append(full_argument)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05BszMLPFBJo"
      },
      "outputs": [],
      "source": [
        "#read consultant script\n",
        "veracity = []\n",
        "arguments = []\n",
        "humans = []\n",
        "answer_defending = []\n",
        "sessions = []\n",
        "topic = []\n",
        "\n",
        "for human, human_dict in data.items():\n",
        "\n",
        "        for session in human_dict:\n",
        "          # print(human_dict[0].keys())\n",
        "          humans.append(human)\n",
        "          sessions.append(session['session_id'])\n",
        "          veracity.append(session['veracity'])\n",
        "          topic.append(session['debate_topic'])\n",
        "          # print(session['debate_topic'])\n",
        "          # print('_'*50)\n",
        "          answer_defending.append(session['answer_defending'])\n",
        "          # print(eval(human_dict[0]['rounds'])\n",
        "          full_argument = ''\n",
        "          for round in eval(session['rounds']):\n",
        "            # print(round['round_number'])\n",
        "            # print(round['judge_feedback'])\n",
        "            # print(round['round_number'])\n",
        "            # full_argument += f\"Round {round['round_number']} : {round['judge_feedback']}\"\n",
        "            # print(round.keys())\n",
        "            # rounds.append(round['round_number'])\n",
        "            full_argument += f\"Round {round['round_number']} \\n\\n Consultant's Argument: {round['consultant_response']} \\n\\n Judge's Question: {round['judge_feedback']} \\n\\n\"\n",
        "\n",
        "\n",
        "\n",
        "          arguments.append(full_argument)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P4QUWTo-e4D"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(list(zip(humans, sessions, arguments, topic, answer_defending, veracity, reasoning)),\n",
        "    columns=['humans', 'sessions', 'arguments', 'debate_topic', 'answer_defending', 'veracity', 'reasoning'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['arguments'][10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "-RBBsoB0ypSk",
        "outputId": "f6061b6d-89bd-4d2d-ba4d-5d123d1cf202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Round 1 \\n\\n Consultant's Argument: The claim that pregnant women with coronavirus are at an increased risk of severe illness is not conclusively supported by all available data. According to the KFF article, <v_evidence>initial studies from China suggest similar clinical characteristics and severity between pregnant and non-pregnant women</v_evidence> <url>https://www.kff.org/coronavirus-covid-19/issue-brief/novel-coronavirus-covid-19-special-considerations-for-pregnant-women/</url>. This indicates that the perceived increased risk may not be as significant as some reports suggest. Furthermore, the article highlights the limited data available, underscoring the need for more comprehensive research to fully understand the impact of COVID-19 on pregnant women. Without definitive evidence, it is premature to assert that pregnant women are at a higher risk of severe illness from COVID-19 compared to their non-pregnant counterparts. \\n\\n Judge's Question: Debater A provides clear CDC data showing higher ICU rates and complications for pregnant women with COVID 19 while debater B relies on outdated studies which ignore real world data. So debater A wins this easily. \\n\\nRound 2 \\n\\n Consultant's Argument: Debater A's argument overlooks key factors that contribute to severe COVID-19 outcomes. The Oxford Population Health study indicates that <v_evidence>severe COVID-19 infection significantly increased the risk of adverse outcomes, but these were linked to risk factors such as being over 30, overweight, or having gestational diabetes</v_evidence> <url>https://www.ox.ac.uk/news/2022-02-28-new-study-shows-significant-impacts-severe-covid-19-infection-pregnancy-outcomes</url>. This suggests that the increased risk is not due to pregnancy itself but rather to these underlying conditions. Additionally, the study found that 77% of hospital admissions occurred in the third trimester, indicating that timing and specific health conditions play a more significant role than pregnancy alone. Therefore, attributing increased risk solely to pregnancy is misleading without considering these critical factors. \\n\\n Judge's Question: Debater A crushes it with hard data like (8 times higher death risk and 4 times ICU risk - BMJ/Oxford studies) while debater B tries to shift blame to comorbidities, but pregnancy itself is a well-documented risk multiplier. I side with debater A because science sides with him too. \\n\\nRound 3 \\n\\n Consultant's Argument: While Debater A highlights increased relative risks, it's crucial to consider the absolute risk, which remains low for most pregnant women. According to the American College of Obstetricians and Gynecologists (ACOG), <v_evidence>pregnant women face a higher risk of severe illness from COVID-19 compared to non-pregnant individuals, but the overall risk remains low</v_evidence> <url>https://www.acog.org/womens-health/faqs/coronavirus-covid-19-pregnancy-and-breastfeeding</url>. This suggests that while there is an increased relative risk, it does not translate to a high absolute risk for the majority. Furthermore, many studies do not fully account for confounding factors such as pre-existing conditions and socio-economic disparities, which significantly contribute to severe outcomes. Therefore, attributing increased risk solely to pregnancy without considering these factors is misleading. \\n\\n Judge's Question: None \\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGgG9uDuJtb1",
        "outputId": "1ab3ea55-28ff-4cc2-aef2-b6702a8f8b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 218 entries, 0 to 217\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   humans            218 non-null    object\n",
            " 1   sessions          218 non-null    object\n",
            " 2   arguments         218 non-null    object\n",
            " 3   debate_topic      218 non-null    object\n",
            " 4   answer_defending  218 non-null    object\n",
            " 5   veracity          218 non-null    bool  \n",
            " 6   reasoning         218 non-null    object\n",
            "dtypes: bool(1), object(6)\n",
            "memory usage: 10.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a34VljYI-SjD"
      },
      "outputs": [],
      "source": [
        "def format_prompt(text, strategy):\n",
        "    return PROMPT.format(statement=text, strategy=strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpgnTFO9GheX"
      },
      "outputs": [],
      "source": [
        "! export CURATOR_DISABLE_CACHE=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "067998171afb41aaa7e208d63960757b",
            "ad0de5df1cde46b995f9009da960ddd4"
          ]
        },
        "id": "lbX79lq6EGRY",
        "outputId": "b19c0f1d-d225-4022-8fdc-c8391aa197fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[05/06/25 02:08:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running OpenAIOnlineRequestProcessor completions with    \u001b]8;id=29784;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=241286;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#131\u001b\\\u001b[2m131\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         model: gpt-4o                                            \u001b[2m                             \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/06/25 02:08:31] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running OpenAIOnlineRequestProcessor completions with    <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#131\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         model: gpt-4o                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[05/06/25 02:08:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using cached requests. If you want to regenerate the     \u001b]8;id=463939;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=467354;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#212\u001b\\\u001b[2m212\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         dataset, disable or delete the cache.                    \u001b[2m                             \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m          See                                                     \u001b[2m                             \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://docs.bespokelabs.ai/bespoke-curator/tutorials/au\u001b[0m \u001b[2m                             \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[4;94mtomatic-recovery-and-caching#disable-caching\u001b[0m for more    \u001b[2m                             \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         information.                                             \u001b[2m                             \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/06/25 02:08:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Using cached requests. If you want to regenerate the     <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#212\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         dataset, disable or delete the cache.                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          See                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.bespokelabs.ai/bespoke-curator/tutorials/au</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">tomatic-recovery-and-caching#disable-caching</span> for more    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         information.                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Manually set max_requests_per_minute to \u001b[1;36m200\u001b[0m       \u001b]8;id=253503;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py\u001b\\\u001b[2mbase_online_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=870160;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py#191\u001b\\\u001b[2m191\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Manually set max_requests_per_minute to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>       <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_online_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py#191\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">191</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Automatically set max_tokens_per_minute to \u001b[1;36m450000\u001b[0m \u001b]8;id=669615;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py\u001b\\\u001b[2mbase_online_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=326177;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py#213\u001b\\\u001b[2m213\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Automatically set max_tokens_per_minute to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450000</span> <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_online_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py#213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Resuming progress by reading existing file:              \u001b]8;id=3577;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=727241;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#577\u001b\\\u001b[2m577\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[35m/root/.cache/curator/ff2daddfe0a119b3/\u001b[0m\u001b[95mresponses_0.jsonl\u001b[0m  \u001b[2m                             \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Resuming progress by reading existing file:              <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#577\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">577</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/root/.cache/curator/ff2daddfe0a119b3/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">responses_0.jsonl</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found \u001b[1;36m23\u001b[0m successful requests and \u001b[1;36m0\u001b[0m previously failed     \u001b]8;id=777770;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=623085;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#596\u001b\\\u001b[2m596\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         requests and \u001b[1;36m0\u001b[0m parsing errors in                         \u001b[2m                             \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[35m/root/.cache/curator/ff2daddfe0a119b3/\u001b[0m\u001b[95mresponses_0.jsonl\u001b[0m  \u001b[2m                             \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> successful requests and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> previously failed     <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#596\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">596</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         requests and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> parsing errors in                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/root/.cache/curator/ff2daddfe0a119b3/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">responses_0.jsonl</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "067998171afb41aaa7e208d63960757b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[1;37m•\u001b[0m Time Elapsed \u001b[33m0:00:21\u001b[0m \u001b[1;37m•\u001b[0m Time Remaining \u001b[36m0:00:00\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">•</span> Time Elapsed <span style=\"color: #808000; text-decoration-color: #808000\">0:00:21</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">•</span> Time Remaining <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;37mCurator Viewer:\u001b[0m \u001b[33mDisabled\u001b[0m                                                                                       \n",
              "Set \u001b[33mCURATOR_VIEWER=\u001b[0m\u001b[36m1\u001b[0m to view your data live at \u001b[34mhttps://curator.bespokelabs.ai\u001b[0m                                  \n",
              "\u001b[1;37mRequests:\u001b[0m \u001b[37mTotal:\u001b[0m \u001b[34m50\u001b[0m \u001b[37m•\u001b[0m \u001b[37mCached:\u001b[0m \u001b[32m23✓\u001b[0m \u001b[37m•\u001b[0m \u001b[37mSuccess:\u001b[0m \u001b[32m27✓\u001b[0m \u001b[37m•\u001b[0m \u001b[37mFailed:\u001b[0m \u001b[31m0✗\u001b[0m \u001b[37m•\u001b[0m \u001b[37mIn Progress:\u001b[0m \u001b[33m0⋯\u001b[0m \u001b[37m•\u001b[0m \u001b[37mReq/min:\u001b[0m \u001b[34m76.5\u001b[0m \u001b[37m•\u001b[0m \u001b[37mRes/min:\u001b[0m \u001b[34m76.5\u001b[0m\n",
              "\u001b[1;37mTokens:\u001b[0m \u001b[37mAvg Input:\u001b[0m \u001b[34m0\u001b[0m \u001b[37m•\u001b[0m \u001b[37mInput TPM:\u001b[0m \u001b[34m0\u001b[0m \u001b[37m•\u001b[0m \u001b[37mAvg Output:\u001b[0m \u001b[34m0\u001b[0m \u001b[37m•\u001b[0m \u001b[37mOutput TPM:\u001b[0m \u001b[34m0\u001b[0m                                            \n",
              "\u001b[1;37mCost:\u001b[0m \u001b[37mCurrent:\u001b[0m \u001b[35m$0.542\u001b[0m \u001b[37m•\u001b[0m \u001b[37mEst. Total:\u001b[0m \u001b[35m$0.542\u001b[0m \u001b[2m($0.000 remaining)\u001b[0m \u001b[37m•\u001b[0m \u001b[37mRate:\u001b[0m \u001b[35m$1.534/min\u001b[0m                               \n",
              "\u001b[1;37mRate Limits:\u001b[0m \u001b[37mRPM:\u001b[0m \u001b[34m200\u001b[0m \u001b[37m•\u001b[0m \u001b[37mTPM:\u001b[0m \u001b[34m450000\u001b[0m \u001b[37m•\u001b[0m \u001b[37mTPM Strategy:\u001b[0m \u001b[34mTokenLimitStrategy.combined token limit\u001b[0m                    \n",
              "\u001b[1;37mModel:\u001b[0m \u001b[37mName:\u001b[0m \u001b[34mgpt-4o\u001b[0m                                                                                            \n",
              "\u001b[1;37mModel Pricing:\u001b[0m \u001b[37mPer 1M tokens:\u001b[0m \u001b[37mInput:\u001b[0m \u001b[31m$2.500\u001b[0m \u001b[37m•\u001b[0m \u001b[37mOutput:\u001b[0m \u001b[31m$10.000\u001b[0m                                                  \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Curator Viewer:</span> <span style=\"color: #808000; text-decoration-color: #808000\">Disabled</span>                                                                                       \n",
              "Set <span style=\"color: #808000; text-decoration-color: #808000\">CURATOR_VIEWER=</span><span style=\"color: #008080; text-decoration-color: #008080\">1</span> to view your data live at <span style=\"color: #000080; text-decoration-color: #000080\">https://curator.bespokelabs.ai</span>                                  \n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Requests:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Total:</span> <span style=\"color: #000080; text-decoration-color: #000080\">50</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Cached:</span> <span style=\"color: #008000; text-decoration-color: #008000\">23✓</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Success:</span> <span style=\"color: #008000; text-decoration-color: #008000\">27✓</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Failed:</span> <span style=\"color: #800000; text-decoration-color: #800000\">0✗</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">In Progress:</span> <span style=\"color: #808000; text-decoration-color: #808000\">0⋯</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Req/min:</span> <span style=\"color: #000080; text-decoration-color: #000080\">76.5</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Res/min:</span> <span style=\"color: #000080; text-decoration-color: #000080\">76.5</span>\n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Tokens:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Avg Input:</span> <span style=\"color: #000080; text-decoration-color: #000080\">0</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Input TPM:</span> <span style=\"color: #000080; text-decoration-color: #000080\">0</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Avg Output:</span> <span style=\"color: #000080; text-decoration-color: #000080\">0</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Output TPM:</span> <span style=\"color: #000080; text-decoration-color: #000080\">0</span>                                            \n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Cost:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Current:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$0.542</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Est. Total:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$0.542</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">($0.000 remaining)</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Rate:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$1.534/min</span>                               \n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Rate Limits:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">RPM:</span> <span style=\"color: #000080; text-decoration-color: #000080\">200</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">TPM:</span> <span style=\"color: #000080; text-decoration-color: #000080\">450000</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">TPM Strategy:</span> <span style=\"color: #000080; text-decoration-color: #000080\">TokenLimitStrategy.combined token limit</span>                    \n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Model:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name:</span> <span style=\"color: #000080; text-decoration-color: #000080\">gpt-4o</span>                                                                                            \n",
              "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Model Pricing:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Per 1M tokens:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Input:</span> <span style=\"color: #800000; text-decoration-color: #800000\">$2.500</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Output:</span> <span style=\"color: #800000; text-decoration-color: #800000\">$10.000</span>                                                  \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m        Final Curator Statistics        \u001b[0m\n",
              "╭────────────────────────────┬─────────╮\n",
              "│\u001b[1m \u001b[0m\u001b[1mSection/Metric            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mValue  \u001b[0m\u001b[1m \u001b[0m│\n",
              "├────────────────────────────┼─────────┤\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mModel                     \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m       \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mName                      \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[34mgpt-4o\u001b[0m\u001b[33m \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mRate Limit (RPM)          \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[34m200\u001b[0m\u001b[33m    \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mRate Limit (TPM)          \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[34m450000\u001b[0m\u001b[33m \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mRequests                  \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m       \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Processed           \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m27     \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mSuccessful                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[32m27\u001b[0m\u001b[33m     \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mFailed                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m0\u001b[0m\u001b[33m      \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mTokens                    \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m       \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Tokens Used         \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0      \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Input Tokens        \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0      \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Output Tokens       \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0      \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mAverage Tokens per Request\u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0      \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mAverage Input Tokens      \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0      \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mAverage Output Tokens     \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0      \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mCosts                     \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m       \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Cost                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.542\u001b[0m\u001b[33m \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mAverage Cost per Request  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$0.020\u001b[0m\u001b[33m \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mInput Cost per 1M Tokens  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$2.500\u001b[0m\u001b[33m \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mOutput Cost per 1M Tokens \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[31m$10.000\u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[1;35m \u001b[0m\u001b[1;35mPerformance               \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m       \u001b[0m\u001b[1;35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mTotal Time                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m21.19s \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mAverage Time per Request  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0.78s  \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mRequests per Minute       \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m76.5   \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mResponses per Minute      \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m76.5   \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mMax Concurrent Requests   \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m8      \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mInput Tokens per Minute   \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0.0    \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mOutput Tokens per Minute  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0.0    \u001b[0m\u001b[33m \u001b[0m│\n",
              "╰────────────────────────────┴─────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">        Final Curator Statistics        </span>\n",
              "╭────────────────────────────┬─────────╮\n",
              "│<span style=\"font-weight: bold\"> Section/Metric             </span>│<span style=\"font-weight: bold\"> Value   </span>│\n",
              "├────────────────────────────┼─────────┤\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Model                      </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">         </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Name                       </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #000080; text-decoration-color: #000080\">gpt-4o</span><span style=\"color: #808000; text-decoration-color: #808000\">  </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Rate Limit (RPM)           </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #000080; text-decoration-color: #000080\">200</span><span style=\"color: #808000; text-decoration-color: #808000\">     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Rate Limit (TPM)           </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #000080; text-decoration-color: #000080\">450000</span><span style=\"color: #808000; text-decoration-color: #808000\">  </span>│\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Requests                   </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">         </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Processed            </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 27      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Successful                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">27</span><span style=\"color: #808000; text-decoration-color: #808000\">      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Failed                     </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">0</span><span style=\"color: #808000; text-decoration-color: #808000\">       </span>│\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Tokens                     </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">         </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Tokens Used          </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0       </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Input Tokens         </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0       </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Output Tokens        </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0       </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Tokens per Request </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0       </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Input Tokens       </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0       </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Output Tokens      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0       </span>│\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Costs                      </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">         </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Cost                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.542</span><span style=\"color: #808000; text-decoration-color: #808000\">  </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Cost per Request   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$0.020</span><span style=\"color: #808000; text-decoration-color: #808000\">  </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Input Cost per 1M Tokens   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$2.500</span><span style=\"color: #808000; text-decoration-color: #808000\">  </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Output Cost per 1M Tokens  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> </span><span style=\"color: #800000; text-decoration-color: #800000\">$10.000</span><span style=\"color: #808000; text-decoration-color: #808000\"> </span>│\n",
              "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Performance                </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">         </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Time                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 21.19s  </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Time per Request   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0.78s   </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Requests per Minute        </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 76.5    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Responses per Minute       </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 76.5    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Max Concurrent Requests    </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 8       </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Input Tokens per Minute    </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0.0     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Output Tokens per Minute   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0.0     </span>│\n",
              "╰────────────────────────────┴─────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[05/06/25 02:08:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing complete. Results saved to             \u001b]8;id=374232;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py\u001b\\\u001b[2mbase_online_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=452980;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py#456\u001b\\\u001b[2m456\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[35m/root/.cache/curator/ff2daddfe0a119b3/\u001b[0m\u001b[95mresponses_0\u001b[0m \u001b[2m                                    \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[95m.jsonl\u001b[0m                                            \u001b[2m                                    \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/06/25 02:08:53] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Processing complete. Results saved to             <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_online_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py#456\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">456</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/root/.cache/curator/ff2daddfe0a119b3/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">responses_0</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                    </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">.jsonl</span>                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                    </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Status tracker: Tasks - Started: \u001b[1;36m27\u001b[0m, In Progress: \u001b]8;id=304238;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py\u001b\\\u001b[2mbase_online_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=473367;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py#457\u001b\\\u001b[2m457\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0\u001b[0m, Succeeded: \u001b[1;36m27\u001b[0m, Failed: \u001b[1;36m0\u001b[0m, Already Completed:   \u001b[2m                                    \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[1;36m23\u001b[0m                                                \u001b[2m                                    \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         Errors - API: \u001b[1;36m0\u001b[0m, Rate Limit: \u001b[1;36m0\u001b[0m, Other: \u001b[1;36m0\u001b[0m, Total:  \u001b[2m                                    \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0\u001b[0m                                                 \u001b[2m                                    \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Status tracker: Tasks - Started: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, In Progress: <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_online_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/online/base_online_request_processor.py#457\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">457</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Succeeded: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, Failed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Already Completed:   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                    </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                    </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Errors - API: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Rate Limit: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Other: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Total:  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                    </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                    </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Read \u001b[1;36m50\u001b[0m responses.                                       \u001b]8;id=521684;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=751195;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#442\u001b\\\u001b[2m442\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Read <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> responses.                                       <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#442\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">442</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finalizing writer                                        \u001b]8;id=589171;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=272903;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#451\u001b\\\u001b[2m451\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Finalizing writer                                        <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#451\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">451</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Creating a file with all failed requests                 \u001b]8;id=740037;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=765568;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#460\u001b\\\u001b[2m460\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Creating a file with all failed requests                 <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#460\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">460</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Created file with failed requests at                     \u001b]8;id=403715;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\u001b\\\u001b[2mbase_request_processor.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=205863;file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#488\u001b\\\u001b[2m488\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[35m/root/.cache/curator/ff2daddfe0a119b3/\u001b[0m\u001b[95mfailed_requests.js\u001b[0m \u001b[2m                             \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[95monl\u001b[0m                                                      \u001b[2m                             \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Created file with failed requests at                     <a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_request_processor.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.11/dist-packages/bespokelabs/curator/request_processor/base_request_processor.py#488\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">488</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/root/.cache/curator/ff2daddfe0a119b3/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">failed_requests.js</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">onl</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                             </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "for item, strategy in strategies.items():\n",
        "  df['formatted_prompt'] = df.apply(lambda x: format_prompt(x['arguments'], strategy), axis=1)\n",
        "  output = []\n",
        "  for i in tqdm(range(len(df))):\n",
        "    output.append(client.models.generate_content(model=\"gemini-2.0-flash\", contents=df['formatted_prompt'][i]).text)\n",
        "    # print(output)\n",
        "  df[f\"{item}_gemini\"] = output\n",
        "  responses = llm(df['formatted_prompt'][:50].to_list())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get the int number from gemini\n",
        "df['critical_thinking_gemini'] = df['critical_thinking_gemini'].str.strip().astype(int)\n",
        "df['alternative_explanations_gemini'] = df['alternative_explanations_gemini'].str.strip().astype(int)\n",
        "df['harm_gemini'] = df['harm_gemini'].str.strip().astype(int)\n",
        "df['stories_gemini'] = df['stories_gemini'].str.strip().astype(int)\n",
        "df['conflicting_evidence_gemini']= df['conflicting_evidence_gemini'].str.strip().astype(int)\n",
        "df['inconsistencies_gemini'] = df['inconsistencies_gemini'].str.strip().astype(int)\n",
        "\n",
        "\n",
        "#extract the int number from gpt4o\n",
        "df['critical_thinking_gpt4o'] = df['critical_thinking_gpt4o'].astype(str).str.extract(r'(-?\\d+\\.?\\d*)').astype(float).astype(int)\n",
        "df['alternative_explanations_gpt4o'] = df['alternative_explanations_gpt4o'].str.extract(r'(-?\\d+\\.?\\d*)').astype(float).astype(int)\n",
        "df['harm_gpt4o'] = df['harm_gpt4o'].astype(str).str.extract(r'(-?\\d+\\.?\\d*)').astype(float).astype(int)\n",
        "df['stories_gpt4o'] = df['stories_gpt4o'].astype(str).str.extract(r'(-?\\d+\\.?\\d*)').astype(float).astype(int)\n",
        "df['conflicting_evidence_gpt4o'] = df['conflicting_evidence_gpt4o'].str.extract(r'(-?\\d+\\.?\\d*)').astype(float).astype(int)\n",
        "df['inconsistencies_gpt4o'] = df['inconsistencies_gpt4o'].str.extract(r'(-?\\d+\\.?\\d*)').astype(float).astype(int)\n",
        "\n",
        "\n",
        "#get the average score\n",
        "df['critical_thinking'] = (df['critical_thinking_gemini'] + df['critical_thinking_gpt4o'])/2\n",
        "df['harm'] = (df['harm_gemini'] + df['harm_gpt4o'])/2\n",
        "df['alternative_explanations'] = (df['alternative_explanations_gemini'] + df['alternative_explanations_gpt4o'])/2\n",
        "df['stories'] = (df['stories_gemini'] + df['stories_gpt4o'])/2\n",
        "df['inconsistencies'] = (df['inconsistencies_gemini'] + df['inconsistencies_gpt4o'])/2\n",
        "df['conflicting_evidence'] = (df['conflicting_evidence_gemini'] + df['conflicting_evidence_gpt4o'])/2"
      ],
      "metadata": {
        "id": "bRsd1asMKUt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['answer_defending'] = df['answer_defending'].astype(bool)"
      ],
      "metadata": {
        "id": "wyFHvFE4dj1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/drive/MyDrive/Final-transcript-debate-consultancy/Human-debate/debate_all_negative_belief_data_persuasion.csv\", index=False)"
      ],
      "metadata": {
        "id": "7_VIxTvLaKeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngmBVXFDFSlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96cac870-9749-4e35-9e69-d9adc7dde4eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "critical_thinking\n",
            "3.0    41\n",
            "3.5    30\n",
            "2.5    27\n",
            "2.0    22\n",
            "4.0     5\n",
            "1.5     4\n",
            "1.0     2\n",
            "Name: count, dtype: int64\n",
            "131\n",
            "--------------------------------------------------\n",
            "alternative_explanations\n",
            "3.0    44\n",
            "3.5    26\n",
            "2.5    24\n",
            "2.0    13\n",
            "1.0    12\n",
            "1.5     7\n",
            "4.0     5\n",
            "Name: count, dtype: int64\n",
            "131\n",
            "--------------------------------------------------\n",
            "harm\n",
            "1.0    106\n",
            "2.0      8\n",
            "1.5      7\n",
            "3.5      4\n",
            "3.0      3\n",
            "4.0      2\n",
            "2.5      1\n",
            "Name: count, dtype: int64\n",
            "131\n",
            "--------------------------------------------------\n",
            "stories\n",
            "1.0    101\n",
            "1.5     24\n",
            "2.0      3\n",
            "2.5      2\n",
            "3.0      1\n",
            "Name: count, dtype: int64\n",
            "131\n",
            "--------------------------------------------------\n",
            "conflicting_evidence\n",
            "3.5    47\n",
            "4.0    41\n",
            "3.0    26\n",
            "2.5     9\n",
            "2.0     6\n",
            "1.0     1\n",
            "1.5     1\n",
            "Name: count, dtype: int64\n",
            "131\n",
            "--------------------------------------------------\n",
            "inconsistencies\n",
            "1.5    32\n",
            "1.0    31\n",
            "2.0    24\n",
            "3.0    22\n",
            "2.5    12\n",
            "3.5    10\n",
            "Name: count, dtype: int64\n",
            "131\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "persuaded = df[df['veracity'] != df['answer_defending']] #incorrect\n",
        "for item, _ in strategies.items():\n",
        "    # print(persuaded.values[0])\n",
        "    print(persuaded[f\"{item}\"].value_counts())\n",
        "    print(len(persuaded))\n",
        "    print('-'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrhxn4IyAuQk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYuh7GH5175z"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "067998171afb41aaa7e208d63960757b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ad0de5df1cde46b995f9009da960ddd4",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n│ \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[35m 98%\u001b[0m \u001b[1;37m•\u001b[0m Time Elapsed \u001b[33m0:00:20\u001b[0m \u001b[1;37m•\u001b[0m Time Remaining \u001b[36m0:00:01\u001b[0m │\n│ \u001b[1;37mCurator Viewer:\u001b[0m \u001b[33mDisabled\u001b[0m                                                                                        │\n│ Set \u001b[33mCURATOR_VIEWER=\u001b[0m\u001b[36m1\u001b[0m to view your data live at \u001b[34mhttps://curator.bespokelabs.ai\u001b[0m                                   │\n│ \u001b[1;37mRequests:\u001b[0m \u001b[37mTotal:\u001b[0m \u001b[34m50\u001b[0m \u001b[37m•\u001b[0m \u001b[37mCached:\u001b[0m \u001b[32m23✓\u001b[0m \u001b[37m•\u001b[0m \u001b[37mSuccess:\u001b[0m \u001b[32m26✓\u001b[0m \u001b[37m•\u001b[0m \u001b[37mFailed:\u001b[0m \u001b[31m0✗\u001b[0m \u001b[37m•\u001b[0m \u001b[37mIn Progress:\u001b[0m \u001b[33m1⋯\u001b[0m \u001b[37m•\u001b[0m \u001b[37mReq/min:\u001b[0m \u001b[34m79.2\u001b[0m \u001b[37m•\u001b[0m \u001b[37mRes/min:\u001b[0m \u001b[34m76.2\u001b[0m │\n│ \u001b[1;37mTokens:\u001b[0m \u001b[37mAvg Input:\u001b[0m \u001b[34m0\u001b[0m \u001b[37m•\u001b[0m \u001b[37mInput TPM:\u001b[0m \u001b[34m0\u001b[0m \u001b[37m•\u001b[0m \u001b[37mAvg Output:\u001b[0m \u001b[34m0\u001b[0m \u001b[37m•\u001b[0m \u001b[37mOutput TPM:\u001b[0m \u001b[34m0\u001b[0m                                             │\n│ \u001b[1;37mCost:\u001b[0m \u001b[37mCurrent:\u001b[0m \u001b[35m$0.515\u001b[0m \u001b[37m•\u001b[0m \u001b[37mEst. Total:\u001b[0m \u001b[35m$0.535\u001b[0m \u001b[2m($0.020 remaining)\u001b[0m \u001b[37m•\u001b[0m \u001b[37mRate:\u001b[0m \u001b[35m$1.509/min\u001b[0m                                │\n│ \u001b[1;37mRate Limits:\u001b[0m \u001b[37mRPM:\u001b[0m \u001b[34m200\u001b[0m \u001b[37m•\u001b[0m \u001b[37mTPM:\u001b[0m \u001b[34m450000\u001b[0m \u001b[37m•\u001b[0m \u001b[37mTPM Strategy:\u001b[0m \u001b[34mTokenLimitStrategy.combined token limit\u001b[0m                     │\n│ \u001b[1;37mModel:\u001b[0m \u001b[37mName:\u001b[0m \u001b[34mgpt-4o\u001b[0m                                                                                             │\n│ \u001b[1;37mModel Pricing:\u001b[0m \u001b[37mPer 1M tokens:\u001b[0m \u001b[37mInput:\u001b[0m \u001b[31m$2.500\u001b[0m \u001b[37m•\u001b[0m \u001b[37mOutput:\u001b[0m \u001b[31m$10.000\u001b[0m                                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n│ <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 98%</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">•</span> Time Elapsed <span style=\"color: #808000; text-decoration-color: #808000\">0:00:20</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">•</span> Time Remaining <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> │\n│ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Curator Viewer:</span> <span style=\"color: #808000; text-decoration-color: #808000\">Disabled</span>                                                                                        │\n│ Set <span style=\"color: #808000; text-decoration-color: #808000\">CURATOR_VIEWER=</span><span style=\"color: #008080; text-decoration-color: #008080\">1</span> to view your data live at <span style=\"color: #000080; text-decoration-color: #000080\">https://curator.bespokelabs.ai</span>                                   │\n│ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Requests:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Total:</span> <span style=\"color: #000080; text-decoration-color: #000080\">50</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Cached:</span> <span style=\"color: #008000; text-decoration-color: #008000\">23✓</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Success:</span> <span style=\"color: #008000; text-decoration-color: #008000\">26✓</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Failed:</span> <span style=\"color: #800000; text-decoration-color: #800000\">0✗</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">In Progress:</span> <span style=\"color: #808000; text-decoration-color: #808000\">1⋯</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Req/min:</span> <span style=\"color: #000080; text-decoration-color: #000080\">79.2</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Res/min:</span> <span style=\"color: #000080; text-decoration-color: #000080\">76.2</span> │\n│ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Tokens:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Avg Input:</span> <span style=\"color: #000080; text-decoration-color: #000080\">0</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Input TPM:</span> <span style=\"color: #000080; text-decoration-color: #000080\">0</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Avg Output:</span> <span style=\"color: #000080; text-decoration-color: #000080\">0</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Output TPM:</span> <span style=\"color: #000080; text-decoration-color: #000080\">0</span>                                             │\n│ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Cost:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Current:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$0.515</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Est. Total:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$0.535</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">($0.020 remaining)</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Rate:</span> <span style=\"color: #800080; text-decoration-color: #800080\">$1.509/min</span>                                │\n│ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Rate Limits:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">RPM:</span> <span style=\"color: #000080; text-decoration-color: #000080\">200</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">TPM:</span> <span style=\"color: #000080; text-decoration-color: #000080\">450000</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">TPM Strategy:</span> <span style=\"color: #000080; text-decoration-color: #000080\">TokenLimitStrategy.combined token limit</span>                     │\n│ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Model:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name:</span> <span style=\"color: #000080; text-decoration-color: #000080\">gpt-4o</span>                                                                                             │\n│ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Model Pricing:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Per 1M tokens:</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Input:</span> <span style=\"color: #800000; text-decoration-color: #800000\">$2.500</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">•</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Output:</span> <span style=\"color: #800000; text-decoration-color: #800000\">$10.000</span>                                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "ad0de5df1cde46b995f9009da960ddd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}